import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import re

# =========================
# 1. 복소수 문자열 → 실수(real)만 추출 함수
# =========================
def extract_real_from_complex_string(s):
    try:
        s = str(s).strip("()").replace(" ", "")
        c = complex(s.replace("−", "-").replace("j", "j"))  # 유니코드 마이너스 등 처리
        return c.real
    except:
        return np.nan

# =========================
# 2. CSV 파일 → (63, 433) ndarray 변환 + feature vector 추출
# =========================
def extract_features_from_csv(csv_path):
    df = pd.read_csv(csv_path)
    csi_cols = [col for col in df.columns if col.startswith("_")]
    df_real = df[csi_cols].apply(lambda col: col.map(extract_real_from_complex_string))
    
    # 통계 기반 feature 추출 (평균, 표준편차, 최대, 최소)
    means = df_real.mean().values
    stds = df_real.std().values
    maxs = df_real.max().values
    mins = df_real.min().values
    feature_vector = np.concatenate([means, stds, maxs, mins])
    return feature_vector

# =========================
# 3. 폴더별 레이블 매핑 + 전체 데이터셋 구축
# =========================
def load_dataset_from_folders(base_path="./data"):
    X = []
    y = []

    folder_label_map = {
        "hands_up": 0,
        "wave_hands": 1
    }

    for folder in os.listdir(base_path):
        folder_path = os.path.join(base_path, folder)
        if not os.path.isdir(folder_path):
            continue

        label = None
        for k in folder_label_map:
            if folder.startswith(k):
                label = folder_label_map[k]
                break
        if label is None:
            continue  # 라벨링 불가한 폴더는 스킵

        for fname in os.listdir(folder_path):
            if not fname.endswith(".csv"):
                continue
            fpath = os.path.join(folder_path, fname)
            features = extract_features_from_csv(fpath)
            X.append(features)
            y.append(label)

    return np.array(X), np.array(y)

# =========================
# 4. 학습 및 평가
# =========================
def train_and_evaluate(X, y):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.3, random_state=42, stratify=y
    )

    clf = SVC(kernel='rbf', C=1.0, gamma='scale')
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    print("=== Classification Report ===")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["hands_up", "wave_hands"],
                yticklabels=["hands_up", "wave_hands"])
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

X, y = load_dataset_from_folders(base_path="/content/drive/MyDrive/Colab Notebooks/")
train_and_evaluate(X, y)

X, y = load_dataset_from_folders(base_path="/content/drive/MyDrive/Colab Notebooks/")
print("총 샘플 수:", len(X))
print("첫 번째 벡터 길이:", len(X[0]) if len(X) > 0 else "없음")
print("레이블 분포:", pd.Series(y).value_counts())
